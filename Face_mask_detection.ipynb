{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sKiLJLn8_0Of"
      },
      "outputs": [],
      "source": [
        "# This project detects face mask from images using Computer Vision.\n",
        "# High-level implementation steps:\n",
        "# 1. Load and preprocess the dataset\n",
        "# 2. Build a CNN model using TensorFlow or PyTorch\n",
        "# 3. Train the model on the dataset\n",
        "# 4. Implement real-time detection using OpenCV"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install kaggle\n",
        "!pip install kaggle"
      ],
      "metadata": {
        "id": "GcVV0oXUqLOM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z4HNIcTqNMVV",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# Creating and saving custom mask detection model\n",
        "# Step 1: Dataset Acquisition\n",
        "\n",
        "# Mount the Google drive so that you can store your Kaggle API credentials\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Create a Kaggle directory\n",
        "!mkdir -p ~/.kaggle\n",
        "\n",
        "# Copy the kaggle.json file to the Kaggle directory\n",
        "!cp /content/drive/MyDrive/Kaggle/kaggle.json ~/.kaggle/\n",
        "\n",
        "# Set permissions for the Kaggle API key\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "# Download the dataset using the Kaggle API\n",
        "!kaggle datasets download -d omkargurav/face-mask-dataset\n",
        "\n",
        "# Unzip the dataset (if needed)\n",
        "!unzip face-mask-dataset.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "LtyMY13hBzGB"
      },
      "outputs": [],
      "source": [
        "# Step 2: Preprocess the dataset\n",
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Define dataset directories\n",
        "with_mask_dir = 'data/with_mask'\n",
        "without_mask_dir = 'data/without_mask'\n",
        "\n",
        "IMG_WIDTH = 128\n",
        "IMG_HEIGHT = 128\n",
        "\n",
        "def load_and_preprocess_images(directory, label):\n",
        "    images = []\n",
        "    labels = []\n",
        "    for img_path in os.listdir(directory):\n",
        "        try:\n",
        "            img = cv2.imread(os.path.join(directory, img_path))\n",
        "            img = tf.image.resize(img, [IMG_WIDTH, IMG_HEIGHT])  # Resize the image\n",
        "\n",
        "            # Check if the image was loaded successfully\n",
        "            if img is None:\n",
        "                print(f\"Warning: Could not read image {img_path}\")\n",
        "                continue\n",
        "\n",
        "            img = img_to_array(img)\n",
        "            images.append(img)\n",
        "            labels.append(label)\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {img_path}: {e}\")\n",
        "            continue\n",
        "    return images, labels\n",
        "\n",
        "# Load images and labels\n",
        "with_mask_images, with_mask_labels = load_and_preprocess_images(with_mask_dir, 1)\n",
        "without_mask_images, without_mask_labels = load_and_preprocess_images(without_mask_dir, 0)\n",
        "\n",
        "# Combine the data\n",
        "images = with_mask_images + without_mask_images\n",
        "labels = with_mask_labels + without_mask_labels\n",
        "\n",
        "# Convert to numpy arrays and normalize\n",
        "images = np.array(images, dtype=\"float32\") / 255.0\n",
        "labels = np.array(labels)\n",
        "\n",
        "print(\"Number of images:\", len(images))\n",
        "print(\"Number of labels:\", len(labels))\n",
        "print(\"Images shape:\", images.shape)\n",
        "print(\"Labels shape:\", labels.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DMTHZUdaCSYp"
      },
      "outputs": [],
      "source": [
        "# Step 3 : Build a CNN Model using Tensorflow\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Assuming 'images' and 'labels' are your data and labels\n",
        "\n",
        "# Split the data into training and testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert to TensorFlow datasets\n",
        "def create_dataset(X, y, batch_size):\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((X, y))\n",
        "    dataset = dataset.shuffle(buffer_size=1000)\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "    return dataset\n",
        "\n",
        "batch_size = 64 # Since larger train_dataset(approx 6000 samples)\n",
        "train_dataset = create_dataset(X_train, y_train, batch_size)\n",
        "test_dataset = create_dataset(X_test, y_test, batch_size)\n",
        "\n",
        "# Create the model\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Flatten(),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    epochs=15,\n",
        "    validation_data=test_dataset\n",
        ")\n",
        "\n",
        "# Save the model\n",
        "model.save('mask_detection_model.keras')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "v1pntjLRDfNC"
      },
      "outputs": [],
      "source": [
        "# Step 5: Implement detection using OpenCV from images\n",
        "from google.colab.patches import cv2_imshow\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
        "\n",
        "# Load the trained model\n",
        "model = load_model('mask_detection_model.keras')\n",
        "\n",
        "# Load the face detection cascade\n",
        "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
        "\n",
        "def detect_mask(image):\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    faces = face_cascade.detectMultiScale(gray, 1.1, 4)\n",
        "\n",
        "    for (x, y, w, h) in faces:\n",
        "        face_roi = image[y:y+h, x:x+w]\n",
        "        face_roi = cv2.resize(face_roi, (128, 128))\n",
        "        face_roi = img_to_array(face_roi)\n",
        "        face_roi = preprocess_input(face_roi)\n",
        "        face_roi = np.expand_dims(face_roi, axis=0)\n",
        "\n",
        "        mask_prob = model.predict(face_roi)[0][0]\n",
        "\n",
        "        if mask_prob > 0.5:\n",
        "            label = f\"Mask: {mask_prob:.2%}\"\n",
        "            color = (0, 255, 0)  # Green for mask\n",
        "        else:\n",
        "            no_mask_prob = 1 - mask_prob\n",
        "            label = f\"No Mask: {no_mask_prob:.2%}\"\n",
        "            color = (0, 0, 255)  # Red for no mask\n",
        "\n",
        "        cv2.putText(image, label, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.45, color, 2)\n",
        "        cv2.rectangle(image, (x, y), (x + w, y + h), color, 2)\n",
        "\n",
        "    return image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CxlRrlpVDyEi"
      },
      "outputs": [],
      "source": [
        "# upload the image using google colab\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "61js86LTD7cI"
      },
      "outputs": [],
      "source": [
        "# Test on an image\n",
        "test_image = cv2.imread('<your_image>')\n",
        "result = detect_mask(test_image)\n",
        "cv2_imshow(result)\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}