{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sKiLJLn8_0Of"
   },
   "outputs": [],
   "source": [
    "# This project detects face mask from images using Computer Vision.\n",
    "# High-level implementation steps:\n",
    "# 1. Load and preprocess the dataset\n",
    "# 2. Build a CNN model using TensorFlow or PyTorch\n",
    "# 3. Train the model on the dataset\n",
    "# 4. Implement real-time detection using OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GcVV0oXUqLOM"
   },
   "outputs": [],
   "source": [
    "# Install kaggle\n",
    "!pip install kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z4HNIcTqNMVV"
   },
   "outputs": [],
   "source": [
    "# Creating and saving custom mask detection model\n",
    "# Step 1: Dataset Acquisition\n",
    "\n",
    "# Mount the Google drive so that you can store your Kaggle API credentials\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Create a Kaggle directory\n",
    "!mkdir -p ~/.kaggle\n",
    "\n",
    "# Copy the kaggle.json file to the Kaggle directory\n",
    "!cp /content/drive/MyDrive/Kaggle/kaggle.json ~/.kaggle/\n",
    "\n",
    "# Set permissions for the Kaggle API key\n",
    "!chmod 600 ~/.kaggle/kaggle.json\n",
    "\n",
    "# Download the dataset using the Kaggle API\n",
    "!kaggle datasets download -d omkargurav/face-mask-dataset\n",
    "\n",
    "# Unzip the dataset (if needed)\n",
    "!unzip face-mask-dataset.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "LtyMY13hBzGB",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "2ab9c207-2781-4ac5-e362-8a814a486450"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images: 7553\n",
      "Number of labels: 7553\n",
      "Images shape: (7553, 224, 224, 3)\n",
      "Labels shape: (7553,)\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Preprocess the dataset\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define dataset directories\n",
    "with_mask_dir = 'data/with_mask'\n",
    "without_mask_dir = 'data/without_mask'\n",
    "\n",
    "IMG_WIDTH = 224\n",
    "IMG_HEIGHT = 224\n",
    "\n",
    "def load_and_preprocess_images(directory, label):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for img_path in os.listdir(directory):\n",
    "        try:\n",
    "            img = cv2.imread(os.path.join(directory, img_path))\n",
    "            img = cv2.resize(img, (IMG_WIDTH, IMG_HEIGHT))\n",
    "\n",
    "            # Check if the image was loaded successfully\n",
    "            if img is None:\n",
    "                print(f\"Warning: Could not read image {img_path}\")\n",
    "                continue\n",
    "\n",
    "            img = img_to_array(img)\n",
    "            images.append(img)\n",
    "            labels.append(label)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {img_path}: {e}\")\n",
    "            continue\n",
    "    return images, labels\n",
    "\n",
    "# Load images and labels\n",
    "with_mask_images, with_mask_labels = load_and_preprocess_images(with_mask_dir, 1)\n",
    "without_mask_images, without_mask_labels = load_and_preprocess_images(without_mask_dir, 0)\n",
    "\n",
    "# Combine the data\n",
    "images = with_mask_images + without_mask_images\n",
    "labels = with_mask_labels + without_mask_labels\n",
    "\n",
    "# Convert to numpy arrays and normalize\n",
    "images = np.array(images, dtype=\"float32\") / 255.0\n",
    "labels = np.array(labels)\n",
    "\n",
    "print(\"Number of images:\", len(images))\n",
    "print(\"Number of labels:\", len(labels))\n",
    "print(\"Images shape:\", images.shape)\n",
    "print(\"Labels shape:\", labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DMTHZUdaCSYp"
   },
   "outputs": [],
   "source": [
    "# Step 3 : Build a CNN Model using Tensorflow\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 15\n",
    "\n",
    "# Define data directories\n",
    "data_dir = 'data/'  # This should contain subdirectories 'with_mask' and 'without_mask'\n",
    "\n",
    "# Create data generators for training and validation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.2  # Split data into training and validation\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=(IMG_WIDTH, IMG_HEIGHT),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    subset='training',\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=(IMG_WIDTH, IMG_HEIGHT),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    subset='validation',\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# Create the CNN model\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(IMG_WIDTH, IMG_HEIGHT, 3)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Add EarlyStopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "# Train the model using the generators\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // BATCH_SIZE,\n",
    "    callbacks=[early_stopping]  # Include EarlyStopping\n",
    ")\n",
    "\n",
    "# Save the model\n",
    "model.save('mask_detection_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v1pntjLRDfNC"
   },
   "outputs": [],
   "source": [
    "# Step 5: Implement detection using OpenCV from images\n",
    "import cv2\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "\n",
    "# Load the trained model\n",
    "model = load_model('mask_detection_model.h5')\n",
    "\n",
    "# Load the face detection cascade\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "def detect_mask(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.1, 4)\n",
    "\n",
    "    for (x, y, w, h) in faces:\n",
    "        face_roi = image[y:y+h, x:x+w]\n",
    "        face_roi = cv2.resize(face_roi, (224, 224))\n",
    "        face_roi = img_to_array(face_roi)\n",
    "        face_roi = preprocess_input(face_roi)\n",
    "        face_roi = np.expand_dims(face_roi, axis=0)\n",
    "\n",
    "        prediction = model.predict(face_roi)[0][0]\n",
    "        label = \"Mask\" if prediction > 0.5 else \"No Mask\"\n",
    "        color = (0, 255, 0) if label == \"Mask\" else (0, 0, 255)\n",
    "\n",
    "        cv2.putText(image, label, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.45, color, 2)\n",
    "        cv2.rectangle(image, (x, y), (x + w, y + h), color, 2)\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CxlRrlpVDyEi"
   },
   "outputs": [],
   "source": [
    "# upload the image using google colab\n",
    "from google.colab import files\n",
    "uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "61js86LTD7cI"
   },
   "outputs": [],
   "source": [
    "# Test on an image\n",
    "test_image = cv2.imread('<your_image>')\n",
    "result = detect_mask(test_image)\n",
    "cv2.imshow('Mask Detection', result)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
